{
  "444": {
    "inputs": {
      "ckpt_name": "realvisxlV40_v30InpaintBakedvae.safetensors"
    },
    "class_type": "CheckpointLoaderSimple",
    "_meta": {
      "title": "Load Checkpoint"
    }
  },
  "445": {
    "inputs": {
      "text": [
        "979",
        0
      ],
      "clip": [
        "444",
        1
      ]
    },
    "class_type": "CLIPTextEncode",
    "_meta": {
      "title": "CLIP Text Encode (Prompt)"
    }
  },
  "446": {
    "inputs": {
      "text": "deformed, watermark, signature, text",
      "clip": [
        "444",
        1
      ]
    },
    "class_type": "CLIPTextEncode",
    "_meta": {
      "title": "CLIP Text Encode (Prompt)"
    }
  },
  "970": {
    "inputs": {
      "ckpt_name": "dreamshaperXL_lightningDPMSDE.safetensors"
    },
    "class_type": "CheckpointLoaderSimple",
    "_meta": {
      "title": "Load Checkpoint"
    }
  },
  "971": {
    "inputs": {
      "text": [
        "980",
        0
      ],
      "clip": [
        "970",
        1
      ]
    },
    "class_type": "CLIPTextEncode",
    "_meta": {
      "title": "CLIP Text Encode (Prompt)"
    }
  },
  "972": {
    "inputs": {
      "guide_size": 384,
      "guide_size_for": true,
      "max_size": 1024,
      "seed": 1073953721129240,
      "steps": 5,
      "cfg": 1.5,
      "sampler_name": "dpmpp_sde",
      "scheduler": "karras",
      "denoise": 0.35000000000000003,
      "feather": 5,
      "noise_mask": true,
      "force_inpaint": true,
      "bbox_threshold": 0.5,
      "bbox_dilation": 10,
      "bbox_crop_factor": 2.5,
      "sam_detection_hint": "center-1",
      "sam_dilation": -10,
      "sam_threshold": 0.93,
      "sam_bbox_expansion": 0,
      "sam_mask_hint_threshold": 0.7,
      "sam_mask_hint_use_negative": "False",
      "drop_size": 10,
      "wildcard": [
        "988",
        0
      ],
      "cycle": 1,
      "inpaint_model": false,
      "noise_mask_feather": 20,
      "image": [
        "1169",
        0
      ],
      "model": [
        "1010",
        0
      ],
      "clip": [
        "970",
        1
      ],
      "vae": [
        "970",
        2
      ],
      "positive": [
        "974",
        0
      ],
      "negative": [
        "975",
        0
      ],
      "bbox_detector": [
        "973",
        0
      ],
      "sam_model_opt": [
        "996",
        0
      ],
      "segm_detector_opt": [
        "973",
        1
      ]
    },
    "class_type": "FaceDetailer",
    "_meta": {
      "title": "FaceDetailer"
    }
  },
  "973": {
    "inputs": {
      "model_name": "bbox/Eyes.pt"
    },
    "class_type": "UltralyticsDetectorProvider",
    "_meta": {
      "title": "UltralyticsDetectorProvider"
    }
  },
  "974": {
    "inputs": {
      "text": "striking eyes",
      "clip": [
        "970",
        1
      ]
    },
    "class_type": "CLIPTextEncode",
    "_meta": {
      "title": "CLIP Text Encode (Prompt)"
    }
  },
  "975": {
    "inputs": {
      "text": "deformed pupils, deformed eyes, ugly eyes",
      "clip": [
        "970",
        1
      ]
    },
    "class_type": "CLIPTextEncode",
    "_meta": {
      "title": "CLIP Text Encode (Prompt)"
    }
  },
  "976": {
    "inputs": {
      "faceanalysis": [
        "977",
        0
      ],
      "image": [
        "993",
        0
      ]
    },
    "class_type": "FaceKeypointsPreprocessor",
    "_meta": {
      "title": "Face Keypoints Preprocessor"
    }
  },
  "977": {
    "inputs": {
      "provider": "CUDA"
    },
    "class_type": "InstantIDFaceAnalysis",
    "_meta": {
      "title": "InstantID Face Analysis"
    }
  },
  "979": {
    "inputs": {
      "prompt": "RAW photo of man age 28, dancing in the club"
    },
    "class_type": "CR Prompt Text",
    "_meta": {
      "title": "‚öôÔ∏è CR Prompt Text - Positive"
    }
  },
  "980": {
    "inputs": {
      "prompt": "nipple, nude, naked, lowres, getty, bad anatomy, bad hands, text, error, missing fingers, extra digit, fewer digits, cropped, worst quality, low quality, normal quality, jpeg artifacts, signature, watermark, username, blurry, artist name, trademark, watermark, title, multiple view, reference sheet, mutated hands and fingers, poorly drawn face, mutation, deformed, ugly, bad proportions, gross proportions, malformed limbs, missing arms, missing legs, extra arms, extra legs, fused fingers, too many fingers, long neck, tatoo, amateur drawing, odd eyes, uneven eyes, unnatural face, uneven nostrils, crooked mouth, bad teeth, crooked teeth, photoshop, video game, censor, censored, ghost, b&w, weird colors, gradient background, spotty background, blurry background, ugly background, simple background, realistic, out of frame, extra objects, tiling, poorly drawn hands, poorly drawn feet, poorly drawn face, out of focus, blurry, very long body, duplicate, morbid, mutilated, extra fingers, mutated hands, poorly drawn eyes, cloned face, disfigured, deformed, cross-eye, extra limbs, missing limb, malformed hands, mutated, morbid, mutilated, disfigured, extra arms, extra hands, mangled fingers, contorted, conjoined, mismatched limbs, mismatched parts, bad perspective, black and white, oversaturated, undersaturated, bad shadow, cropped image, draft, grainy, pixelated"
    },
    "class_type": "CR Prompt Text",
    "_meta": {
      "title": "‚öôÔ∏è CR Prompt Text - Negative"
    }
  },
  "983": {
    "inputs": {
      "seed": 1231234239
    },
    "class_type": "Seed",
    "_meta": {
      "title": "Global Seed"
    }
  },
  "988": {
    "inputs": {
      "prompt": ""
    },
    "class_type": "CR Prompt Text",
    "_meta": {
      "title": "Eye Enhancer prompt"
    }
  },
  "991": {
    "inputs": {
      "image": "myheadshotfunny.jpg",
      "upload": "image"
    },
    "class_type": "LoadImage",
    "_meta": {
      "title": "Load Image"
    }
  },
  "992": {
    "inputs": {
      "seed": [
        "983",
        3
      ],
      "steps": 4,
      "cfg": 1.5,
      "sampler_name": "dpmpp_sde_gpu",
      "scheduler": "karras",
      "denoise": 0.9500000000000001,
      "model": [
        "970",
        0
      ],
      "positive": [
        "1021",
        0
      ],
      "negative": [
        "971",
        0
      ],
      "latent_image": [
        "995",
        0
      ]
    },
    "class_type": "KSampler",
    "_meta": {
      "title": "KSampler"
    }
  },
  "993": {
    "inputs": {
      "samples": [
        "992",
        0
      ],
      "vae": [
        "970",
        2
      ]
    },
    "class_type": "VAEDecode",
    "_meta": {
      "title": "VAE Decode"
    }
  },
  "995": {
    "inputs": {
      "width": 512,
      "height": 512,
      "batch_size": 1
    },
    "class_type": "EmptyLatentImage",
    "_meta": {
      "title": "Empty Latent Image"
    }
  },
  "996": {
    "inputs": {
      "model_name": "sam_vit_b_01ec64.pth",
      "device_mode": "Prefer GPU"
    },
    "class_type": "SAMLoader",
    "_meta": {
      "title": "SAMLoader (Impact)"
    }
  },
  "1000": {
    "inputs": {
      "control_net_name": "instantid-controlnet.safetensors"
    },
    "class_type": "ControlNetLoader",
    "_meta": {
      "title": "Load ControlNet Model"
    }
  },
  "1001": {
    "inputs": {
      "weight": 0.81,
      "start_at": 0.001,
      "end_at": 0.999,
      "instantid": [
        "1002",
        0
      ],
      "insightface": [
        "1003",
        0
      ],
      "control_net": [
        "1000",
        0
      ],
      "image": [
        "991",
        0
      ],
      "model": [
        "970",
        0
      ],
      "positive": [
        "1011",
        0
      ],
      "negative": [
        "971",
        0
      ],
      "image_kps": [
        "1279",
        0
      ]
    },
    "class_type": "ApplyInstantID",
    "_meta": {
      "title": "Apply InstantID"
    }
  },
  "1002": {
    "inputs": {
      "instantid_file": "instantid-ip-adapter.bin"
    },
    "class_type": "InstantIDModelLoader",
    "_meta": {
      "title": "Load InstantID Model"
    }
  },
  "1003": {
    "inputs": {
      "provider": "CUDA"
    },
    "class_type": "InstantIDFaceAnalysis",
    "_meta": {
      "title": "InstantID Face Analysis"
    }
  },
  "1005": {
    "inputs": {
      "samples": [
        "1006",
        0
      ],
      "vae": [
        "970",
        2
      ]
    },
    "class_type": "VAEDecode",
    "_meta": {
      "title": "VAE Decode"
    }
  },
  "1006": {
    "inputs": {
      "seed": 760055130669875,
      "steps": 5,
      "cfg": 1.2,
      "sampler_name": "dpmpp_sde_gpu",
      "scheduler": "karras",
      "denoise": 0.9500000000000001,
      "model": [
        "1010",
        0
      ],
      "positive": [
        "1001",
        1
      ],
      "negative": [
        "1001",
        2
      ],
      "latent_image": [
        "1276",
        0
      ]
    },
    "class_type": "KSampler",
    "_meta": {
      "title": "KSampler"
    }
  },
  "1008": {
    "inputs": {
      "preset": "FACEID PLUS V2",
      "lora_strength": 0.6,
      "provider": "CPU",
      "model": [
        "1001",
        0
      ]
    },
    "class_type": "IPAdapterUnifiedLoaderFaceID",
    "_meta": {
      "title": "IPAdapter Unified Loader FaceID"
    }
  },
  "1009": {
    "inputs": {
      "weight": 0.5,
      "weight_faceidv2": 1,
      "weight_type": "linear",
      "combine_embeds": "concat",
      "start_at": 0,
      "end_at": 1,
      "embeds_scaling": "V only",
      "model": [
        "1008",
        0
      ],
      "ipadapter": [
        "1008",
        1
      ],
      "image": [
        "991",
        0
      ]
    },
    "class_type": "IPAdapterFaceID",
    "_meta": {
      "title": "IPAdapter FaceID"
    }
  },
  "1010": {
    "inputs": {
      "tonemap_multiplier": 8,
      "rescale_multiplier": 0.62,
      "model": [
        "1009",
        0
      ]
    },
    "class_type": "TonemapNoiseWithRescaleCFG",
    "_meta": {
      "title": "TonemapNoiseWithRescaleCFG"
    }
  },
  "1011": {
    "inputs": {
      "text": [
        "979",
        0
      ],
      "clip": [
        "970",
        1
      ]
    },
    "class_type": "CLIPTextEncode",
    "_meta": {
      "title": "CLIP Text Encode (Prompt)"
    }
  },
  "1015": {
    "inputs": {
      "upscale_method": "lanczos",
      "scale_by": 1.5,
      "image": [
        "972",
        0
      ]
    },
    "class_type": "ImageScaleBy",
    "_meta": {
      "title": "Upscale Image By"
    }
  },
  "1016": {
    "inputs": {
      "brightness": 0,
      "contrast": 1,
      "saturation": 1,
      "sharpness": 1.1,
      "blur": 0,
      "gaussian_blur": 0,
      "edge_enhance": 0.1,
      "detail_enhance": "true",
      "image": [
        "1015",
        0
      ]
    },
    "class_type": "Image Filter Adjustments",
    "_meta": {
      "title": "Image Filter Adjustments"
    }
  },
  "1021": {
    "inputs": {
      "text": [
        "979",
        0
      ],
      "clip": [
        "970",
        1
      ]
    },
    "class_type": "CLIPTextEncode",
    "_meta": {
      "title": "CLIP Text Encode (Prompt)"
    }
  },
  "1078": {
    "inputs": {
      "seed": [
        "983",
        3
      ],
      "steps": [
        "1166",
        0
      ],
      "cfg": 3.5,
      "sampler_name": "dpmpp_2m_sde_gpu",
      "scheduler": "karras",
      "denoise": 0.8,
      "model": [
        "444",
        0
      ],
      "positive": [
        "1080",
        0
      ],
      "negative": [
        "1080",
        1
      ],
      "latent_image": [
        "1080",
        3
      ]
    },
    "class_type": "KSampler",
    "_meta": {
      "title": "KSampler"
    }
  },
  "1079": {
    "inputs": {
      "samples": [
        "1078",
        0
      ],
      "vae": [
        "444",
        2
      ]
    },
    "class_type": "VAEDecode",
    "_meta": {
      "title": "VAE Decode"
    }
  },
  "1080": {
    "inputs": {
      "positive": [
        "445",
        0
      ],
      "negative": [
        "446",
        0
      ],
      "vae": [
        "444",
        2
      ],
      "pixels": [
        "1113",
        0
      ],
      "mask": [
        "1123",
        0
      ]
    },
    "class_type": "INPAINT_VAEEncodeInpaintConditioning",
    "_meta": {
      "title": "VAE Encode & Inpaint Conditioning"
    }
  },
  "1092": {
    "inputs": {
      "expand": 10,
      "tapered_corners": true,
      "mask": [
        "1100",
        1
      ]
    },
    "class_type": "GrowMask",
    "_meta": {
      "title": "GrowMask"
    }
  },
  "1098": {
    "inputs": {
      "model_name": "sam2_hiera_large.pt"
    },
    "class_type": "SAM2ModelLoader (segment anything)",
    "_meta": {
      "title": "SAM2ModelLoader (segment anything)"
    }
  },
  "1099": {
    "inputs": {
      "model_name": "GroundingDINO_SwinB (938MB)"
    },
    "class_type": "GroundingDinoModelLoader (segment anything)",
    "_meta": {
      "title": "GroundingDinoModelLoader (segment anything)"
    }
  },
  "1100": {
    "inputs": {
      "prompt": "watermark signature",
      "threshold": [
        "1309",
        1
      ],
      "sam_model": [
        "1098",
        0
      ],
      "grounding_dino_model": [
        "1099",
        0
      ],
      "image": [
        "1113",
        0
      ]
    },
    "class_type": "GroundingDinoSAMSegment (segment anything)",
    "_meta": {
      "title": "GroundingDinoSAMSegment (segment anything)"
    }
  },
  "1113": {
    "inputs": {
      "x": 0,
      "y": 0,
      "resize_source": true,
      "destination": [
        "1005",
        0
      ],
      "source": [
        "1127",
        0
      ],
      "mask": [
        "1114",
        0
      ]
    },
    "class_type": "ImageCompositeMasked",
    "_meta": {
      "title": "ImageCompositeMasked"
    }
  },
  "1114": {
    "inputs": {
      "image": "common_watermark_mask.png",
      "channel": "red",
      "upload": "image"
    },
    "class_type": "LoadImageMask",
    "_meta": {
      "title": "Load Image (as Mask)"
    }
  },
  "1120": {
    "inputs": {
      "image": "common_watermark_image.png",
      "upload": "image"
    },
    "class_type": "LoadImage",
    "_meta": {
      "title": "Load Image"
    }
  },
  "1123": {
    "inputs": {
      "mask1": [
        "1228",
        0
      ],
      "mask2": [
        "1193",
        1
      ]
    },
    "class_type": "AddMask",
    "_meta": {
      "title": "Pixelwise(MASK + MASK)"
    }
  },
  "1127": {
    "inputs": {
      "blend_factor": 0.6,
      "blend_mode": "normal",
      "image1": [
        "1005",
        0
      ],
      "image2": [
        "1120",
        0
      ]
    },
    "class_type": "ImageBlend",
    "_meta": {
      "title": "ImageBlend"
    }
  },
  "1157": {
    "inputs": {
      "value": 7
    },
    "class_type": "JWInteger",
    "_meta": {
      "title": "Steps"
    }
  },
  "1158": {
    "inputs": {
      "model": "microsoft/Florence-2-base-ft",
      "precision": "fp16",
      "attention": "sdpa"
    },
    "class_type": "DownloadAndLoadFlorence2Model",
    "_meta": {
      "title": "DownloadAndLoadFlorence2Model"
    }
  },
  "1159": {
    "inputs": {
      "text_input": "person, head, body, signature, watermark, watermark",
      "task": "caption_to_phrase_grounding",
      "fill_mask": true,
      "keep_model_loaded": true,
      "max_new_tokens": 1024,
      "num_beams": 1,
      "do_sample": true,
      "output_mask_select": "",
      "image": [
        "1005",
        0
      ],
      "florence2_model": [
        "1221",
        0
      ]
    },
    "class_type": "Florence2Run",
    "_meta": {
      "title": "Florence2Run"
    }
  },
  "1161": {
    "inputs": {
      "text": [
        "1159",
        2
      ],
      "sub_text": "watermark",
      "case_insensitive": true
    },
    "class_type": "Text Contains",
    "_meta": {
      "title": "Text Contains"
    }
  },
  "1162": {
    "inputs": {
      "boolean": [
        "1225",
        0
      ],
      "number_a": [
        "1163",
        0
      ],
      "number_b": [
        "1164",
        0
      ]
    },
    "class_type": "Number Input Switch",
    "_meta": {
      "title": "Number Input Switch"
    }
  },
  "1163": {
    "inputs": {
      "a": 1
    },
    "class_type": "CM_IntToNumber",
    "_meta": {
      "title": "IntToNumber"
    }
  },
  "1164": {
    "inputs": {
      "a": 0
    },
    "class_type": "CM_IntToNumber",
    "_meta": {
      "title": "IntToNumber"
    }
  },
  "1166": {
    "inputs": {
      "a": [
        "1157",
        0
      ],
      "b": [
        "1162",
        2
      ]
    },
    "class_type": "JWIntegerMul",
    "_meta": {
      "title": "Integer Multiply"
    }
  },
  "1168": {
    "inputs": {
      "input": [
        "1162",
        2
      ],
      "output": ""
    },
    "class_type": "Display Int (rgthree)",
    "_meta": {
      "title": "Display Int (rgthree)"
    }
  },
  "1169": {
    "inputs": {
      "Input": [
        "1178",
        0
      ],
      "image1": [
        "1005",
        0
      ],
      "image2": [
        "1079",
        0
      ]
    },
    "class_type": "CR Image Input Switch",
    "_meta": {
      "title": "üîÄ CR Image Input Switch"
    }
  },
  "1175": {
    "inputs": {
      "print_to_console": false,
      "console_title": "",
      "execute": "Always",
      "text": [
        "1159",
        2
      ],
      "display": " person<loc_0><loc_0><loc_842><loc_998>head<loc_95><loc_0><loc_516><loc_438>body<loc_0><loc_389><loc_686><loc_998>watermark<loc_597><loc_634><loc_749><loc_697>"
    },
    "class_type": "ttN textDebug",
    "_meta": {
      "title": "textDebug"
    }
  },
  "1178": {
    "inputs": {
      "index": [
        "1162",
        2
      ],
      "interval": 1
    },
    "class_type": "CR Index Increment",
    "_meta": {
      "title": "üî¢ CR Index Increment"
    }
  },
  "1193": {
    "inputs": {
      "select": [
        "1197",
        0
      ],
      "images1": [
        "1113",
        0
      ],
      "mask1_opt": [
        "1228",
        0
      ],
      "mask2_opt": [
        "1092",
        0
      ]
    },
    "class_type": "ImageMaskSwitch",
    "_meta": {
      "title": "Switch (images, mask)"
    }
  },
  "1197": {
    "inputs": {
      "index": [
        "1162",
        2
      ],
      "interval": 1
    },
    "class_type": "CR Index Increment",
    "_meta": {
      "title": "üî¢ CR Index Increment"
    }
  },
  "1206": {
    "inputs": {
      "float": 0.3
    },
    "class_type": "ttN float",
    "_meta": {
      "title": "SAM2 Thresh"
    }
  },
  "1208": {
    "inputs": {
      "Value": [
        "1162",
        2
      ]
    },
    "class_type": "DF_Int_to_Float",
    "_meta": {
      "title": "Int to Float"
    }
  },
  "1221": {
    "inputs": {
      "model": "microsoft/Florence-2-large",
      "precision": "fp16",
      "attention": "sdpa"
    },
    "class_type": "DownloadAndLoadFlorence2Model",
    "_meta": {
      "title": "DownloadAndLoadFlorence2Model"
    }
  },
  "1223": {
    "inputs": {
      "text": [
        "1159",
        2
      ],
      "sub_text": "signature",
      "case_insensitive": true
    },
    "class_type": "Text Contains",
    "_meta": {
      "title": "Text Contains"
    }
  },
  "1225": {
    "inputs": {
      "boolean_a": [
        "1161",
        0
      ],
      "boolean_b": [
        "1223",
        0
      ]
    },
    "class_type": "Logic Comparison OR",
    "_meta": {
      "title": "Logic Comparison OR"
    }
  },
  "1228": {
    "inputs": {
      "expand": 4,
      "tapered_corners": true,
      "mask": [
        "1114",
        0
      ]
    },
    "class_type": "GrowMask",
    "_meta": {
      "title": "GrowMask"
    }
  },
  "1253": {
    "inputs": {
      "filename_prefix": "FinalOutput",
      "images": [
        "1016",
        0
      ]
    },
    "class_type": "SaveImage",
    "_meta": {
      "title": "Save Image"
    }
  },
  "1261": {
    "inputs": {
      "crop_size_margin": 2,
      "crop_pos_margin": 0.5,
      "image": [
        "976",
        0
      ]
    },
    "class_type": "JCo_CropAroundKPS",
    "_meta": {
      "title": "Prep Crop Around Keypoints"
    }
  },
  "1262": {
    "inputs": {
      "x": [
        "1261",
        2
      ],
      "y": [
        "1261",
        3
      ],
      "width": [
        "1261",
        0
      ],
      "height": [
        "1261",
        1
      ],
      "image": [
        "976",
        0
      ]
    },
    "class_type": "ETN_CropImage",
    "_meta": {
      "title": "Crop Image"
    }
  },
  "1264": {
    "inputs": {
      "x": [
        "1261",
        2
      ],
      "y": [
        "1261",
        3
      ],
      "width": [
        "1261",
        0
      ],
      "height": [
        "1261",
        1
      ],
      "image": [
        "993",
        0
      ]
    },
    "class_type": "ETN_CropImage",
    "_meta": {
      "title": "Crop Image"
    }
  },
  "1275": {
    "inputs": {
      "pixels": [
        "1264",
        0
      ],
      "vae": [
        "970",
        2
      ]
    },
    "class_type": "VAEEncode",
    "_meta": {
      "title": "VAE Encode"
    }
  },
  "1276": {
    "inputs": {
      "blend_factor": 0.75,
      "samples1": [
        "1278",
        0
      ],
      "samples2": [
        "1277",
        0
      ]
    },
    "class_type": "LatentBlend",
    "_meta": {
      "title": "Latent Blend"
    }
  },
  "1277": {
    "inputs": {
      "width": 1024,
      "height": 1024,
      "batch_size": 1
    },
    "class_type": "EmptyLatentImage",
    "_meta": {
      "title": "Empty Latent Image"
    }
  },
  "1278": {
    "inputs": {
      "upscale_method": "nearest-exact",
      "width": 1024,
      "height": 1024,
      "crop": "disabled",
      "samples": [
        "1275",
        0
      ]
    },
    "class_type": "LatentUpscale",
    "_meta": {
      "title": "Upscale Latent"
    }
  },
  "1279": {
    "inputs": {
      "upscale_method": "nearest-exact",
      "width": 1024,
      "height": 1024,
      "crop": "disabled",
      "image": [
        "1262",
        0
      ]
    },
    "class_type": "ImageScale",
    "_meta": {
      "title": "Upscale Image"
    }
  },
  "1309": {
    "inputs": {
      "value": "1 - a * (1 - b)",
      "a": [
        "1208",
        0
      ],
      "b": [
        "1206",
        0
      ]
    },
    "class_type": "SimpleMath+",
    "_meta": {
      "title": "üîß Simple Math"
    }
  }
}